{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Classification\n",
    "By: Jared Berry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always') # To deal with 'UndefinedMetric' warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\lightgbm\\__init__.py:30: ResourceWarning: unclosed file <_io.TextIOWrapper name='C:\\\\Users\\\\jared\\\\Anaconda3\\\\lib\\\\site-packages\\\\lightgbm\\\\VERSION.txt' mode='r' encoding='cp1252'>\n",
      "  __version__ = open(os.path.join(dir_path, 'VERSION.txt')).read().strip()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# I/O and data structures\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Evaluation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Quality of life\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modeling helper functions\n",
    "from modeling_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "inpath = \"model_dictionary.pickle\"\n",
    "with open(inpath, 'rb') as f:\n",
    "    modeling = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['target_1_return', 'target_1_return_res', 'target_1_composite', 'target_1_average', 'target_1_rank', 'target_1_up', 'target_1_rel_return', 'target_5_return', 'target_5_return_res', 'target_5_composite', 'target_5_average', 'target_5_rank', 'target_5_up', 'target_5_rel_return', 'target_10_return', 'target_10_return_res', 'target_10_composite', 'target_10_average', 'target_10_rank', 'target_10_up', 'target_10_rel_return', 'target_21_return', 'target_21_return_res', 'target_21_composite', 'target_21_average', 'target_21_rank', 'target_21_up', 'target_21_rel_return', 'features', 'ticker_features'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out the features dataframe\n",
    "train = modeling['features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a feature selection list (THINK ABOUT INFORMING THIS SELECTION WITH SHRINKAGE METHODS, I.E. RIDGE REGRESSION)\n",
    "features = ['High', 'Low', 'Open', 'Close', 'Volume', 'AdjClose', 'Year',\n",
    "            'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Pct_Change_Daily',\n",
    "            'Pct_Change_Monthly', 'Pct_Change_Yearly', 'RSI', 'Volatility',\n",
    "            'Yearly_Return_Rank', 'Monthly_Return_Rank', 'Pct_Change_Class',\n",
    "            'Rolling_Yearly_Mean_Positive_Days', 'Rolling_Monthly_Mean_Positive_Days', \n",
    "            'Rolling_Monthly_Mean_Price', 'Rolling_Yearly_Mean_Price',\n",
    "            'Momentum_Quality_Monthly', 'Momentum_Quality_Yearly', 'SPY_Trailing_Month_Return',\n",
    "            'open_l1', 'open_l5', 'open_l10', 'close_l1', 'close_l5', 'close_l10',\n",
    "            'return_prev1_open_raw', 'return_prev5_open_raw', 'return_prev10_open_raw',\n",
    "            'return_prev1_close_raw', 'return_prev5_close_raw', 'return_prev10_close_raw',\n",
    "            'pe_ratio', 'debt_ratio', 'debt_to_equity', 'roa',\n",
    "            'beta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select on features to pass to modeling machinery, along with necessary indexers\n",
    "X = train[features]\n",
    "tickers = train['ticker'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a ticker\n",
    "target = modeling['target_21_rel_return']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Panel-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that there are bound to be a number of systemic considerations that impact the price of a stock at any given point in time, it is prudent to perform and evaluate predictions across the panel of S&P 500 stocks in our sample, which will capture potential linkages between different stocks, and allow us to explore the possibility of using features generated from clustering to group like stocks in the panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies for panel-level regressions\n",
    "X_p = X.copy(deep=True)\n",
    "y_p = target.copy()\n",
    "\n",
    "# Indexes of hold-out test data (the 21 days of data preceding the present day)\n",
    "test_idx = np.where(np.isnan(y_p))[0].tolist()\n",
    "\n",
    "# In order to ensure grouping is done properly, remove this data from a ticker-identification set as well\n",
    "ticker_locs = train['ticker'].drop(train.index[test_idx]).reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple feature-scaling - for now, replace missings with 0 (i.e. the mean of a normalized feature) within days\n",
    "X_p = X_p.groupby(['Year', 'Month', 'Day']).apply(lambda x: (x - np.mean(x))/np.std(x)).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove hold-out test data\n",
    "y_p = np.delete(y_p, test_idx)\n",
    "X_p_holdout = X_p.loc[X_p.index[test_idx]]\n",
    "X_p = X_p.drop(X_p.index[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p_smoothed = np.zeros(y_p.shape[0])\n",
    "for t in tickers:\n",
    "    idx = ticker_locs.loc[ticker_locs['ticker'] == t].index.tolist()\n",
    "    y_to_smooth = y_p[idx]\n",
    "    \n",
    "    # Compute EMA smoothing of target within ticker\n",
    "    EMA = 0\n",
    "    gamma_ = 1\n",
    "    for ti in range(len(y_to_smooth)):\n",
    "        EMA = gamma_*y_to_smooth[ti] + (1-gamma_)*EMA\n",
    "        y_to_smooth[ti] = EMA\n",
    "        \n",
    "    y_p_smoothed[idx] = y_to_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p_smoothed = y_p.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 targets changed by smoothing.\n",
      "===============================================================================\n",
      "Baseline, one-class accuracy is: 57.99999999999999%\n",
      "Classification report for one-class predictor:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    413409\n",
      "           1       0.58      1.00      0.73    561385\n",
      "\n",
      "   micro avg       0.58      0.58      0.58    974794\n",
      "   macro avg       0.29      0.50      0.37    974794\n",
      "weighted avg       0.33      0.58      0.42    974794\n",
      "\n",
      "Baseline, random-walk accuracy is: 57.99999999999999%\n",
      "Classification report for random-walk predictor:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.51      0.51    413203\n",
      "           1       0.64      0.64      0.64    561092\n",
      "\n",
      "   micro avg       0.58      0.58      0.58    974295\n",
      "   macro avg       0.57      0.57      0.57    974295\n",
      "weighted avg       0.58      0.58      0.58    974295\n",
      "\n",
      "===============================================================================\n",
      "Training model on validation split #1\n",
      "Training model on validation split #2\n",
      "Training model on validation split #3\n",
      "Training model on validation split #4\n",
      "Training model on validation split #5\n",
      "Training model on validation split #6\n",
      "Training model on validation split #7\n",
      "Training model on validation split #8\n",
      "Training model on validation split #9\n",
      "Training model on validation split #10\n",
      "Training model on validation split #11\n",
      "Training model on validation split #12\n",
      "Build, hyperparameter selection, and validation of LGBM Classifier took 112.487 seconds\n",
      "\n",
      "Average AUC across 12 splits: 0.5029816425879344\n",
      "Average accuracy across 12 splits: 49.0%\n",
      "('Volume', 3.25)\n",
      "('beta', 2.25)\n",
      "('open_l10', 0.08333333333333333)\n",
      "('High', 0.0)\n",
      "('Low', 0.0)\n",
      "('Open', 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate - gamma MUST be 1 here\n",
    "fit_lgbm_classifier(X_p, y_p_smoothed, X_p_holdout, ticker=\"\", ema_gamma=1, n_splits=12, export=False, \n",
    "                    valid_method = 'panel', groups = ticker_locs)\n",
    "## fit_sklearn_classifier(X_p, y_p_smoothed, X_p_holdout, ticker=\"\", ema_gamma=1, valid_splits=12, model=GradientBoostingClassifier,\n",
    "##                        label='kNN Classifier', param_search = {}, export=False, \n",
    "##                        panel = True, groups=ticker_locs, n_estimators = 1000, learning_rate = 0.01, max_depth=2\n",
    "##                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ticker-level "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the heart of this analysis is a time-series prediction problem. As such, it is prudent to explore running models for each individual stock. We can envision averaging the results of both modeling approaches to incorporate the contribution of both into a final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in enumerate(tickers[:5]):\n",
    "    \n",
    "    # Pull only feature/target data for the relevant stocker\n",
    "    X_t = X.loc[train['ticker'] == t,:]\n",
    "    y_t = np.array(target)[train['ticker'] == t]\n",
    "    \n",
    "    # Indexes of hold-out test data (the 21 days of data preceding the present day)\n",
    "    test_idx = np.where(np.isnan(y_t))[0].tolist()\n",
    "    \n",
    "    # Simple feature-scaling - for now, replace missings with 0 (i.e. the mean of a normalized feature)\n",
    "    X_t = X_t.apply(lambda x: (x - np.mean(x))/np.std(x)).fillna(0)\n",
    "    \n",
    "    # Remove hold-out test data\n",
    "    y_t = np.delete(y_t, test_idx)\n",
    "    X_t_holdout = X_t.loc[X_t.index[test_idx]]\n",
    "    X_t = X_t.drop(X_t.index[test_idx])\n",
    "    \n",
    "    # Fit and evaluate\n",
    "    fit_lgbm_classifier(X_t, y_t, X_t_holdout, ticker=t, ema_gamma=1, valid_splits=12, export=False, valid_method='ts', labeled = False)\n",
    "    #fit_sklearn_classifier(X_t, y_t, X_t_holdout, ticker=t, ema_gamma=1, n_splits=12, model=GradientBoostingClassifier,\n",
    "    #                       label='kNN Classifier', param_search = {}, export=False, n_estimators = 1000, \n",
    "    #                       learning_rate = 0.01, max_depth = 1\n",
    "    #                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
