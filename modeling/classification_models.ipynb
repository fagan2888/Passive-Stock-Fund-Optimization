{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Classification\n",
    "\n",
    "Credits for inspiration for plot code:  \n",
    "https://stackoverflow.com/questions/28200786/how-to-plot-scikit-learn-classification-report  \n",
    "https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python  \n",
    "https://stackoverflow.com/questions/29656550/how-to-plot-pr-curve-over-10-folds-of-cross-validation-in-scikit-learn\n",
    "\n",
    "By: Jared Berry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality of life\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "# I/O and data structures\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Evaluation\n",
    "from sklearn import metrics\n",
    "import statsmodels.tsa.stattools as ts\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modeling helper functions\n",
    "from modeling_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "inpath = \"model_dictionary.pickle\"\n",
    "with open(inpath, 'rb') as f:\n",
    "    modeling = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out the features dataframe\n",
    "train = modeling['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove tickers with fewer than 5-years worth of data\n",
    "ticker_counts = (train['ticker']\n",
    "                 .value_counts()\n",
    "                 .reset_index()\n",
    "                 .rename({'ticker':'count','index':'ticker'}, axis=1))\n",
    "keep_tickers = (ticker_counts\n",
    "                .loc[ticker_counts['count'] >= (252*5), 'ticker']\n",
    "                .tolist())\n",
    "keep_idx = train['ticker'].isin(keep_tickers)\n",
    "train = train[keep_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a feature selection list (THINK ABOUT INFORMING THIS SELECTION WITH SHRINKAGE METHODS, I.E. LASSO REGRESSION)\n",
    "features = ['High', 'Low', 'Close', 'Volume', 'AdjClose', 'Year',\n",
    "            'Month', 'Week', 'Day', 'Dayofyear', \n",
    "            'Pct_Change_Monthly', 'Pct_Change_Yearly', 'RSI', 'Volatility',\n",
    "            'Yearly_Return_Rank', 'Monthly_Return_Rank',\n",
    "            'Rolling_Yearly_Mean_Positive_Days', 'Rolling_Monthly_Mean_Positive_Days', \n",
    "            'Rolling_Monthly_Mean_Price', 'Rolling_Yearly_Mean_Price',\n",
    "            'Momentum_Quality_Monthly', 'Momentum_Quality_Yearly', 'SPY_Trailing_Month_Return',\n",
    "            'open_l10',  'return_prev5_close_raw', 'return_prev10_close_raw',\n",
    "            'pe_ratio', 'debt_ratio', 'roa',\n",
    "            'beta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select on features to pass to modeling machinery, along with necessary indexers\n",
    "X = train[features]\n",
    "tickers = train['ticker'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a ticker - remove the tickers as above\n",
    "target = modeling['target_21_rel_return']\n",
    "target = target[keep_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Panel-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that there are bound to be a number of systemic considerations that impact the price of a stock at any given point in time, it is prudent to perform and evaluate predictions across the panel of S&P 500 stocks in our sample, which will capture potential linkages between different stocks, and allow us to explore the possibility of using features generated from clustering to group like stocks in the panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a panel-level copy\n",
    "y_p = target.copy()\n",
    "\n",
    "# Indexes of hold-out test data (the 21 days of data preceding the present day)\n",
    "test_idx = np.where(np.isnan(y_p))[0].tolist()\n",
    "\n",
    "# In order to ensure grouping is done properly, remove this data from a ticker-identification set as well\n",
    "ticker_locs = (train[['ticker','date_of_transaction']]\n",
    "               .drop(train.index[test_idx])\n",
    "               .reset_index()\n",
    "               .drop('index', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a panel-level copy; normalize by day\n",
    "X_p = X.copy(deep=True)\n",
    "X_p = (X_p.groupby(['Year', 'Month', 'Day'])\n",
    "       .apply(lambda x: (x - np.mean(x))/np.std(x))\n",
    "       .fillna(0)\n",
    "       .drop(['Year', 'Month', 'Day'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove hold-out test data\n",
    "y_p = np.delete(y_p, test_idx)\n",
    "X_p_holdout = X_p.loc[X_p.index[test_idx]]\n",
    "X_p = X_p.drop(X_p.index[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential Moving Average smoothing (skip if not)\n",
    "y_p_smoothed = np.zeros(y_p.shape[0])\n",
    "for t in tickers:\n",
    "    idx = ticker_locs.loc[ticker_locs['ticker'] == t].index.tolist()\n",
    "    y_to_smooth = y_p[idx]\n",
    "    \n",
    "    # Compute EMA smoothing of target within ticker\n",
    "    EMA = 0\n",
    "    gamma_ = 1\n",
    "    for ti in range(len(y_to_smooth)):\n",
    "        EMA = gamma_*y_to_smooth[ti] + (1-gamma_)*EMA\n",
    "        y_to_smooth[ti] = EMA\n",
    "        \n",
    "    y_p_smoothed[idx] = y_to_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM\n",
    "model_dict = fit_lgbm_classifier(X_p, \n",
    "                                 y_p_smoothed, \n",
    "                                 X_p_holdout, \n",
    "                                 ticker=\"\", \n",
    "                                 ema_gamma=1, \n",
    "                                 n_splits=12,\n",
    "                                 cv_method='ts',\n",
    "                                 groups=ticker_locs, \n",
    "                                 labeled=False,\n",
    "                                 label=\"lgbm_final\",\n",
    "                                 param_search=None,\n",
    "                                 holdout_method='distributed',\n",
    "                                 threshold_search=True,\n",
    "                                 export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN\n",
    "model_dict = fit_sklearn_classifier(X_p, \n",
    "                                    y_p, \n",
    "                                    X_p_holdout, \n",
    "                                    ticker=\"\", \n",
    "                                    ema_gamma=1, \n",
    "                                    n_splits=12,\n",
    "                                    cv_method='panel',\n",
    "                                    model=KNeighborsClassifier,\n",
    "                                    groups=ticker_locs, \n",
    "                                    label='kNN Classifier', \n",
    "                                    param_search=None,\n",
    "                                    holdout_method='distributed',\n",
    "                                    threshold_search=False,\n",
    "                                    n_jobs=-1,\n",
    "                                    export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model_dict['preds_df']\n",
    "test = test[test['split_number'] != 0]\n",
    "print(metrics.confusion_matrix(test['expected'], test['predicted']))\n",
    "print(metrics.roc_auc_score(test['expected'], test['predicted']))\n",
    "print(metrics.classification_report(test['expected'], test['predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ticker-level "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the heart of this analysis is a time-series prediction problem. As such, it is prudent to explore running models for each individual stock. We can envision averaging the results of both modeling approaches to incorporate the contribution of both into a final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "cv_method_ = 'tswindow'\n",
    "label_ = 'lgbm_final'\n",
    "results_dfs = []\n",
    "for i, t in enumerate(tickers[:5]):\n",
    "    \n",
    "    # Pull only feature/target data for the relevant stocker\n",
    "    X_t = X.loc[train['ticker'] == t,:].drop(['Year', 'Month', 'Day'], axis=1)\n",
    "    y_t = np.array(target)[train['ticker'] == t]\n",
    "    \n",
    "    # Indexes of hold-out test data (the 21 days of data preceding the present day)\n",
    "    test_idx = np.where(np.isnan(y_t))[0].tolist()\n",
    "    \n",
    "    # Simple feature-scaling - for now, replace missings with 0 (i.e. the mean of a normalized feature)\n",
    "    X_t = X_t.apply(lambda x: (x - np.mean(x))/np.std(x)).fillna(0)\n",
    "    \n",
    "    # Remove hold-out test data\n",
    "    y_t = np.delete(y_t, test_idx)\n",
    "    y_t = np.array((pd.Series(y_t) - pd.Series(y_t).shift()).fillna(0).tolist())\n",
    "    X_t_holdout = X_t.loc[X_t.index[test_idx]]\n",
    "    X_t = X_t.drop(X_t.index[test_idx])\n",
    "    \n",
    "    # Fit and evaluate\n",
    "    model_dict = fit_lgbm_classifier(X_t, \n",
    "                                     y_t,\n",
    "                                     X_t_holdout, \n",
    "                                     ticker=t, \n",
    "                                     ema_gamma=1, \n",
    "                                     n_splits=12,\n",
    "                                     cv_method='tswindow', \n",
    "                                     labeled=False,\n",
    "                                     param_search=None,\n",
    "                                     holdout_method='distributed',\n",
    "                                     threshold_search=True,\n",
    "                                     export=False)\n",
    "    \n",
    "    results_dfs.append(model_dict)\n",
    "    \n",
    "(pd.Series(y_t) - pd.Series(y_t).shift())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export ticker-level models\n",
    "model_outpath = \"{}_{}_{}.pickle\".format(slugify(label_), \"all_tickers_\", cv_method_)\n",
    "with open(model_outpath, 'wb') as f:\n",
    "    pickle.dump(results_dfs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "cv_method_ = 'ts'\n",
    "label_ = 'RF Window'\n",
    "model_ = RandomForestClassifier\n",
    "\n",
    "results_dfs = []\n",
    "for i, t in enumerate(tickers):\n",
    "    \n",
    "    # Pull only feature/target data for the relevant stocker\n",
    "    X_t = X.loc[train['ticker'] == t,:].drop(['Year', 'Month', 'Day'], axis=1)\n",
    "    y_t = np.array(target)[train['ticker'] == t]\n",
    "    \n",
    "    # Indexes of hold-out test data (the 21 days of data preceding the present day)\n",
    "    test_idx = np.where(np.isnan(y_t))[0].tolist()\n",
    "    \n",
    "    # Simple feature-scaling - for now, replace missings with 0 (i.e. the mean of a normalized feature)\n",
    "    X_t = X_t.apply(lambda x: (x - np.mean(x))/np.std(x)).fillna(0)\n",
    "    \n",
    "    # Remove hold-out test data\n",
    "    y_t = np.delete(y_t, test_idx)\n",
    "    X_t_holdout = X_t.loc[X_t.index[test_idx]]\n",
    "    X_t = X_t.drop(X_t.index[test_idx])\n",
    "    \n",
    "    # Fit and evaluate\n",
    "    model_dict = fit_sklearn_classifier(X_t, \n",
    "                                        y_t, \n",
    "                                        X_t_holdout, \n",
    "                                        ticker=t, \n",
    "                                        ema_gamma=1, \n",
    "                                        n_splits=36,\n",
    "                                        cv_method=cv_method_,\n",
    "                                        model=model_,\n",
    "                                        label=label_, \n",
    "                                        param_search=None,\n",
    "                                        holdout_method='distributed',\n",
    "                                        threshold_search=True,\n",
    "                                        n_estimators=1000,\n",
    "                                        export=False)\n",
    "    \n",
    "    results_dfs.append(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export ticker-level models\n",
    "model_outpath = \"{}_{}_{}.pickle\".format(slugify(label_), \"all_tickers\", cv_method_)\n",
    "with open(model_outpath, 'wb') as f:\n",
    "    pickle.dump(results_dfs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Panel-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to pickle file containing panel-level model\n",
    "model_inpath = \"lgbm_final_select_panel_ts.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "with open(model_inpath, 'rb') as f:\n",
    "    results_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_performance = results_df['preds_df']\n",
    "try:\n",
    "    feature_importances = pd.DataFrame(results_df['feature_importances'], columns=['feature', 'importance'])\n",
    "except KeyError:\n",
    "    print(\"No variable importances for this model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ticker-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to pickle file containing ticker-level model\n",
    "model_inpath = \"lgbm_final_all_tickers_252_21_tswindow.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "with open(model_inpath, 'rb') as f:\n",
    "    results_dfs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stand up results dataframes\n",
    "performance_dfs = []\n",
    "feature_importance_dfs = []\n",
    "holdout_predictions = defaultdict(list)\n",
    "\n",
    "for r in results_dfs:\n",
    "    performance_dfs.append(r['preds_df'])\n",
    "    try:\n",
    "        feature_importance_dfs.append(pd.DataFrame(r['feature_importances'], columns=['feature', 'importance']))\n",
    "    except KeyError:\n",
    "        print(\"No variable importances for this model\")\n",
    "    holdout_predictions[r['preds_df'].ticker.unique().tolist()[0]] = r['holdout_probs']\n",
    "    \n",
    "ticker_performance = pd.concat(performance_dfs, axis=0)\n",
    "feature_importances = pd.concat(feature_importance_dfs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unpopulated splits (training data never used for validation)\n",
    "ticker_performance = ticker_performance[ticker_performance['split_number'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average feature importances across all ticker-level models\n",
    "average_importances = feature_importances.groupby('feature').mean().sort_values('importance')\n",
    "average_importances.plot(kind='barh', title=\"Feature Importances - Ticker\", legend=False, figsize=(16,12))\n",
    "plt.savefig(fname='varimp_tickers_252_63_final.jpg', pad_inches=0, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC Curve\n",
    "fpr, tpr, threshold = metrics.roc_curve(ticker_performance['expected'], ticker_performance['predicted_prob'])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.plot(fpr, tpr, 'c', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig(fname='auc_ticker_lgbm_252_21_final.jpg', pad_inches=0, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curves\n",
    "precision, recall, _ = metrics.precision_recall_curve(ticker_performance['expected'], ticker_performance['predicted_prob'], pos_label=1)\n",
    "average_precision = metrics.average_precision_score(ticker_performance['expected'], ticker_performance['predicted_prob'])\n",
    "\n",
    "plt.plot(recall, precision, label='area = %0.2f' % average_precision, color=\"green\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Recall Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(fname='prc_ticker_lgbm_252_126_final.jpg', pad_inches=0, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "import matplotlib.pyplot as plt\n",
    "scores = metrics.precision_recall_fscore_support(ticker_performance['expected'], ticker_performance['predicted'])\n",
    "score_matrix = [[s[0] for s in scores[:3]],\n",
    "                [s[1] for s in scores[:3]]]\n",
    "print(score_matrix)\n",
    "\n",
    "plt.imshow(score_matrix, interpolation='nearest', cmap='RdBu_r', vmin=0, vmax=1)\n",
    "plt.title('LightGBM Classification Report - window CV')\n",
    "plt.colorbar()\n",
    "x_tick_marks = np.arange(3)\n",
    "y_tick_marks = np.arange(2)\n",
    "plt.xticks(x_tick_marks, ['precision', 'recall', 'f1-score'], rotation=45, )\n",
    "ax.yaxis.label.set_size(25)\n",
    "ax.xaxis.label.set_size(25)\n",
    "ax.set_title('LightGBM Classification Report - window CV', size=20)\n",
    "plt.yticks(y_tick_marks, ['Outperform', 'Underperform'])\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Classes')\n",
    "plt.xlabel('Measures')\n",
    "plt.savefig(fname='lgbm_window_map_ticker_252_21_final.jpg', pad_inches=0, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(ticker_performance['expected'], ticker_performance['predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
