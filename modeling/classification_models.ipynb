{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Classification\n",
    "By: Jared Berry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always') # To deal with 'UndefinedMetric' warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\lightgbm\\__init__.py:30: ResourceWarning: unclosed file <_io.TextIOWrapper name='C:\\\\Users\\\\jared\\\\Anaconda3\\\\lib\\\\site-packages\\\\lightgbm\\\\VERSION.txt' mode='r' encoding='cp1252'>\n",
      "  __version__ = open(os.path.join(dir_path, 'VERSION.txt')).read().strip()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# I/O and data structures\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Evaluation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Quality of life\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modeling helper functions\n",
    "from modeling_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "inpath = \"model_dictionary.pickle\"\n",
    "with open(inpath, 'rb') as f:\n",
    "    modeling = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['target_1_return', 'target_1_return_res', 'target_1_composite', 'target_1_average', 'target_1_rank', 'target_1_up', 'target_1_rel_return', 'target_5_return', 'target_5_return_res', 'target_5_composite', 'target_5_average', 'target_5_rank', 'target_5_up', 'target_5_rel_return', 'target_10_return', 'target_10_return_res', 'target_10_composite', 'target_10_average', 'target_10_rank', 'target_10_up', 'target_10_rel_return', 'target_21_return', 'target_21_return_res', 'target_21_composite', 'target_21_average', 'target_21_rank', 'target_21_up', 'target_21_rel_return', 'features', 'ticker_features'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out the features dataframe\n",
    "train = modeling['features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a feature selection list (THINK ABOUT INFORMING THIS SELECTION WITH SHRINKAGE METHODS, I.E. RIDGE REGRESSION)\n",
    "features = ['High', 'Low', 'Open', 'Close', 'Volume', 'AdjClose', 'Year',\n",
    "            'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Pct_Change_Daily',\n",
    "            'Pct_Change_Monthly', 'Pct_Change_Yearly', 'RSI', 'Volatility',\n",
    "            'Yearly_Return_Rank', 'Monthly_Return_Rank', 'Pct_Change_Class',\n",
    "            'Rolling_Yearly_Mean_Positive_Days', 'Rolling_Monthly_Mean_Positive_Days', \n",
    "            'Rolling_Monthly_Mean_Price', 'Rolling_Yearly_Mean_Price',\n",
    "            'Momentum_Quality_Monthly', 'Momentum_Quality_Yearly', 'SPY_Trailing_Month_Return',\n",
    "            'open_l1', 'open_l5', 'open_l10', 'close_l1', 'close_l5', 'close_l10',\n",
    "            'return_prev1_open_raw', 'return_prev5_open_raw', 'return_prev10_open_raw',\n",
    "            'return_prev1_close_raw', 'return_prev5_close_raw', 'return_prev10_close_raw',\n",
    "            'pe_ratio', 'debt_ratio', 'debt_to_equity', 'roa',\n",
    "            'beta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select on features to pass to modeling machinery, along with necessary indexers\n",
    "X = train[features]\n",
    "tickers = train['ticker'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a ticker\n",
    "target = modeling['target_21_rel_return']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Panel-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that there are bound to be a number of systemic considerations that impact the price of a stock at any given point in time, it is prudent to perform and evaluate predictions across the panel of S&P 500 stocks in our sample, which will capture potential linkages between different stocks, and allow us to explore the possibility of using features generated from clustering to group like stocks in the panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a panel-level copy\n",
    "y_p = target.copy()\n",
    "\n",
    "# Indexes of hold-out test data (the 21 days of data preceding the present day)\n",
    "test_idx = np.where(np.isnan(y_p))[0].tolist()\n",
    "\n",
    "# In order to ensure grouping is done properly, remove this data from a ticker-identification set as well\n",
    "ticker_locs = train['ticker'].drop(train.index[test_idx]).reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a panel-level copy\n",
    "X_p = X.copy(deep=True)\n",
    "\n",
    "# Simple feature-scaling - for now, replace missings with 0 (i.e. the mean of a normalized feature) within days\n",
    "X_p = X_p.groupby(['Year', 'Month', 'Day']).apply(lambda x: (x - np.mean(x))/np.std(x)).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove hold-out test data\n",
    "y_p = np.delete(y_p, test_idx)\n",
    "X_p_holdout = X_p.loc[X_p.index[test_idx]]\n",
    "X_p = X_p.drop(X_p.index[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p_smoothed = np.zeros(y_p.shape[0])\n",
    "for t in tickers:\n",
    "    idx = ticker_locs.loc[ticker_locs['ticker'] == t].index.tolist()\n",
    "    y_to_smooth = y_p[idx]\n",
    "    \n",
    "    # Compute EMA smoothing of target within ticker\n",
    "    EMA = 0\n",
    "    gamma_ = 0.75\n",
    "    for ti in range(len(y_to_smooth)):\n",
    "        EMA = gamma_*y_to_smooth[ti] + (1-gamma_)*EMA\n",
    "        y_to_smooth[ti] = EMA\n",
    "        \n",
    "    y_p_smoothed[idx] = y_to_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p_smoothed = y_p.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 targets changed by smoothing.\n",
      "===============================================================================\n",
      "Baseline, one-class accuracy is: 50.0%\n",
      "Classification report for one-class predictor:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    490499\n",
      "           1       0.50      1.00      0.67    495151\n",
      "\n",
      "   micro avg       0.50      0.50      0.50    985650\n",
      "   macro avg       0.25      0.50      0.33    985650\n",
      "weighted avg       0.25      0.50      0.34    985650\n",
      "\n",
      "Baseline, random-walk accuracy is: 61.0%\n",
      "Classification report for random-walk predictor:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61    490235\n",
      "           1       0.61      0.61      0.61    494911\n",
      "\n",
      "   micro avg       0.61      0.61      0.61    985146\n",
      "   macro avg       0.61      0.61      0.61    985146\n",
      "weighted avg       0.61      0.61      0.61    985146\n",
      "\n",
      "===============================================================================\n",
      "Training model on validation split #1\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate - gamma MUST be 1 here\n",
    "## fit_lgbm_classifier(X_p, y_p_smoothed, X_p_holdout, ticker=\"\", ema_gamma=1, n_splits=12, export=False, \n",
    "##                     valid_method = 'panel', groups = ticker_locs, labeled = False)\n",
    "fit_sklearn_classifier(X_p, y_p_smoothed, X_p_holdout, ticker=\"\", ema_gamma=1, n_splits=12, model=KNeighborsClassifier,\n",
    "                       label='kNN Classifier', param_search = {}, export=False, labeled=False, groups=ticker_locs,\n",
    "                       cv_method='panel'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ticker-level "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the heart of this analysis is a time-series prediction problem. As such, it is prudent to explore running models for each individual stock. We can envision averaging the results of both modeling approaches to incorporate the contribution of both into a final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 targets changed by smoothing.\n",
      "===============================================================================\n",
      "Baseline, one-class accuracy is: 56.00000000000001%\n",
      "Classification report for one-class predictor:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       885\n",
      "           1       0.56      1.00      0.72      1130\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      2015\n",
      "   macro avg       0.28      0.50      0.36      2015\n",
      "weighted avg       0.31      0.56      0.40      2015\n",
      "\n",
      "Baseline, random-walk accuracy is: 48.0%\n",
      "Classification report for random-walk predictor:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.41      0.41       885\n",
      "           1       0.54      0.54      0.54      1129\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      2014\n",
      "   macro avg       0.47      0.47      0.47      2014\n",
      "weighted avg       0.48      0.48      0.48      2014\n",
      "\n",
      "===============================================================================\n",
      "Performing grid search for hyperparameter tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on validation split #1\n",
      "Training model on validation split #2\n",
      "Training model on validation split #3\n",
      "Training model on validation split #4\n",
      "Training model on validation split #5\n",
      "Training model on validation split #6\n",
      "Training model on validation split #7\n",
      "Training model on validation split #8\n",
      "Training model on validation split #9\n",
      "Training model on validation split #10\n",
      "Training model on validation split #11\n",
      "Training model on validation split #12\n",
      "Build, hyperparameter selection, and validation of kNN Classifier took 16.511 seconds\n",
      "\n",
      "Hyperparameters are as follows:\n",
      "n_neighbors: 10\n",
      "\n",
      "Validation scores are as follows:\n",
      "precision    0.512573\n",
      "recall       0.529570\n",
      "accuracy     0.529570\n",
      "f1           0.485275\n",
      "dtype: float64\n",
      "\n",
      "0 targets changed by smoothing.\n",
      "===============================================================================\n",
      "Baseline, one-class accuracy is: 59.0%\n",
      "Classification report for one-class predictor:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       828\n",
      "           1       0.59      1.00      0.74      1187\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      2015\n",
      "   macro avg       0.29      0.50      0.37      2015\n",
      "weighted avg       0.35      0.59      0.44      2015\n",
      "\n",
      "Baseline, random-walk accuracy is: 51.0%\n",
      "Classification report for random-walk predictor:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.41      0.41       828\n",
      "           1       0.59      0.59      0.59      1186\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      2014\n",
      "   macro avg       0.50      0.50      0.50      2014\n",
      "weighted avg       0.51      0.51      0.51      2014\n",
      "\n",
      "===============================================================================\n",
      "Performing grid search for hyperparameter tuning\n",
      "Training model on validation split #1\n",
      "Training model on validation split #2\n",
      "Training model on validation split #3\n",
      "Training model on validation split #4\n",
      "Training model on validation split #5\n",
      "Training model on validation split #6\n",
      "Training model on validation split #7\n",
      "Training model on validation split #8\n",
      "Training model on validation split #9\n",
      "Training model on validation split #10\n",
      "Training model on validation split #11\n",
      "Training model on validation split #12\n",
      "Build, hyperparameter selection, and validation of kNN Classifier took 16.787 seconds\n",
      "\n",
      "Hyperparameters are as follows:\n",
      "n_neighbors: 10\n",
      "\n",
      "Validation scores are as follows:\n",
      "precision    0.540977\n",
      "recall       0.569892\n",
      "accuracy     0.569892\n",
      "f1           0.514432\n",
      "dtype: float64\n",
      "\n",
      "0 targets changed by smoothing.\n",
      "===============================================================================\n",
      "Baseline, one-class accuracy is: 57.99999999999999%\n",
      "Classification report for one-class predictor:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       838\n",
      "           1       0.58      1.00      0.74      1177\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      2015\n",
      "   macro avg       0.29      0.50      0.37      2015\n",
      "weighted avg       0.34      0.58      0.43      2015\n",
      "\n",
      "Baseline, random-walk accuracy is: 52.0%\n",
      "Classification report for random-walk predictor:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.42      0.42       838\n",
      "           1       0.59      0.59      0.59      1176\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      2014\n",
      "   macro avg       0.51      0.51      0.51      2014\n",
      "weighted avg       0.52      0.52      0.52      2014\n",
      "\n",
      "===============================================================================\n",
      "Performing grid search for hyperparameter tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on validation split #1\n",
      "Training model on validation split #2\n",
      "Training model on validation split #3\n",
      "Training model on validation split #4\n",
      "Training model on validation split #5\n",
      "Training model on validation split #6\n",
      "Training model on validation split #7\n",
      "Training model on validation split #8\n",
      "Training model on validation split #9\n",
      "Training model on validation split #10\n",
      "Training model on validation split #11\n",
      "Training model on validation split #12\n",
      "Build, hyperparameter selection, and validation of kNN Classifier took 16.988 seconds\n",
      "\n",
      "Hyperparameters are as follows:\n",
      "n_neighbors: 10\n",
      "\n",
      "Validation scores are as follows:\n",
      "precision    0.504884\n",
      "recall       0.561828\n",
      "accuracy     0.561828\n",
      "f1           0.496860\n",
      "dtype: float64\n",
      "\n",
      "0 targets changed by smoothing.\n",
      "===============================================================================\n",
      "Baseline, one-class accuracy is: 56.99999999999999%\n",
      "Classification report for one-class predictor:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       875\n",
      "           1       0.57      1.00      0.72      1140\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      2015\n",
      "   macro avg       0.28      0.50      0.36      2015\n",
      "weighted avg       0.32      0.57      0.41      2015\n",
      "\n",
      "Baseline, random-walk accuracy is: 54.0%\n",
      "Classification report for random-walk predictor:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.47      0.47       874\n",
      "           1       0.59      0.59      0.59      1140\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      2014\n",
      "   macro avg       0.53      0.53      0.53      2014\n",
      "weighted avg       0.54      0.54      0.54      2014\n",
      "\n",
      "===============================================================================\n",
      "Performing grid search for hyperparameter tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on validation split #1\n",
      "Training model on validation split #2\n",
      "Training model on validation split #3\n",
      "Training model on validation split #4\n",
      "Training model on validation split #5\n",
      "Training model on validation split #6\n",
      "Training model on validation split #7\n",
      "Training model on validation split #8\n",
      "Training model on validation split #9\n",
      "Training model on validation split #10\n",
      "Training model on validation split #11\n",
      "Training model on validation split #12\n",
      "Build, hyperparameter selection, and validation of kNN Classifier took 17.125 seconds\n",
      "\n",
      "Hyperparameters are as follows:\n",
      "n_neighbors: 4\n",
      "\n",
      "Validation scores are as follows:\n",
      "precision    0.513656\n",
      "recall       0.538172\n",
      "accuracy     0.538172\n",
      "f1           0.486208\n",
      "dtype: float64\n",
      "\n",
      "0 targets changed by smoothing.\n",
      "===============================================================================\n",
      "Baseline, one-class accuracy is: 55.00000000000001%\n",
      "Classification report for one-class predictor:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       706\n",
      "           1       0.55      1.00      0.71       868\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      1574\n",
      "   macro avg       0.28      0.50      0.36      1574\n",
      "weighted avg       0.30      0.55      0.39      1574\n",
      "\n",
      "Baseline, random-walk accuracy is: 54.0%\n",
      "Classification report for random-walk predictor:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.48      0.48       706\n",
      "           1       0.58      0.58      0.58       867\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      1573\n",
      "   macro avg       0.53      0.53      0.53      1573\n",
      "weighted avg       0.54      0.54      0.54      1573\n",
      "\n",
      "===============================================================================\n",
      "Performing grid search for hyperparameter tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\jared\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on validation split #1\n",
      "Training model on validation split #2\n",
      "Training model on validation split #3\n",
      "Training model on validation split #4\n",
      "Training model on validation split #5\n",
      "Training model on validation split #6\n",
      "Training model on validation split #7\n",
      "Training model on validation split #8\n",
      "Training model on validation split #9\n",
      "Training model on validation split #10\n",
      "Training model on validation split #11\n",
      "Training model on validation split #12\n",
      "Build, hyperparameter selection, and validation of kNN Classifier took 11.621 seconds\n",
      "\n",
      "Hyperparameters are as follows:\n",
      "n_neighbors: 4\n",
      "\n",
      "Validation scores are as follows:\n",
      "precision    0.519550\n",
      "recall       0.537879\n",
      "accuracy     0.537879\n",
      "f1           0.494314\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(tickers[:5]):\n",
    "    \n",
    "    # Pull only feature/target data for the relevant stocker\n",
    "    X_t = X.loc[train['ticker'] == t,:]\n",
    "    y_t = np.array(target)[train['ticker'] == t]\n",
    "    \n",
    "    # Indexes of hold-out test data (the 21 days of data preceding the present day)\n",
    "    test_idx = np.where(np.isnan(y_t))[0].tolist()\n",
    "    \n",
    "    # Simple feature-scaling - for now, replace missings with 0 (i.e. the mean of a normalized feature)\n",
    "    X_t = X_t.apply(lambda x: (x - np.mean(x))/np.std(x)).fillna(0)\n",
    "    \n",
    "    # Remove hold-out test data\n",
    "    y_t = np.delete(y_t, test_idx)\n",
    "    X_t_holdout = X_t.loc[X_t.index[test_idx]]\n",
    "    X_t = X_t.drop(X_t.index[test_idx])\n",
    "    \n",
    "    # Fit and evaluate\n",
    "    #fit_lgbm_classifier(X_t, y_t, X_t_holdout, ticker=t, ema_gamma=1, valid_splits=12, export=False, valid_method='ts', labeled = False)\n",
    "    fit_sklearn_classifier(X_t, y_t, X_t_holdout, ticker=t, ema_gamma=1, n_splits=12, model=KNeighborsClassifier,\n",
    "                           label='kNN Classifier', param_search = {'n_neighbors':[2,4,6,8,10]}, \n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
